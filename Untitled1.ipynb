{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9030c014",
   "metadata": {
    "cellId": "dg2vertgp8ndlyjf3vju75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d515980e",
   "metadata": {
    "cellId": "po1ky13mkdf5q1xp0y752e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "−    10192\n",
       "+     6262\n",
       "?     2907\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/takimov/MLTinkoff/master/train.csv')\n",
    "     \n",
    "batch_1 = df\n",
    "\n",
    "batch_1['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e003aa88",
   "metadata": {
    "cellId": "6wn76zn98erg0vtxkarquq"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "df_test = pd.read_csv('https://raw.githubusercontent.com/GitSanyaHub/HSE_HACK/main/new_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e77813bd",
   "metadata": {
    "cellId": "v32tzrgoqedz9p87jl8fmp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18362"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sum(batch_1['2category'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "78b66a68",
   "metadata": {
    "cellId": "jwzrhgni1wlw5trmb6wvp"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kernel/lib/python3.8/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: Kernel cannot be interrupted during state load\n",
      "  warnings.warn(self._warn_message)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=int64)' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-4e11fc48b790>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbatch_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbatch_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'−'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'+'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'?'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'texts'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_tes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'texts'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mbatch_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4359\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m     ):\n\u001b[0;32m-> 4361\u001b[0;31m         return super().replace(\n\u001b[0m\u001b[1;32m   4362\u001b[0m             \u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6679\u001b[0m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6681\u001b[0;31m             return self.replace(\n\u001b[0m\u001b[1;32m   6682\u001b[0m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6683\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4359\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m     ):\n\u001b[0;32m-> 4361\u001b[0;31m         return super().replace(\n\u001b[0m\u001b[1;32m   4362\u001b[0m             \u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6730\u001b[0m                         )\n\u001b[1;32m   6731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6732\u001b[0;31m                     new_data = self._data.replace_list(\n\u001b[0m\u001b[1;32m   6733\u001b[0m                         \u001b[0msrc_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6734\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, regex)\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masm8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 )\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex)\u001b[0m\n\u001b[1;32m   1963\u001b[0m             \u001b[0mtype_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ndarray(dtype={dtype})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \"Cannot compare types {a!r} and {b!r}\".format(\n\u001b[1;32m   1967\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# очистка текста\n",
    "def clean_text(text):\n",
    "    # приведение текста к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # удаление знаков пунктуации и специальных символов\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # токенизация\n",
    "    tokens = word_tokenize(text)\n",
    "    # удаление стоп-слов\n",
    "    stop_words = set(stopwords.words('russian'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # лемматизация\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    text = ' '.join(lemmatized_tokens)\n",
    "    return text\n",
    "\n",
    "batch_1['sentence'] = batch_1['sentence'].apply(clean_text)\n",
    "batch_1['sentiment'] = batch_1['sentiment'].replace({'−': -1, '+': 1, '?': 0}).astype(int)\n",
    "\n",
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e4cd68e4",
   "metadata": {
    "cellId": "qesjbiysbvp0j4pg6oe1zn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "df_test['texts'] = df_test['texts'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c771d209",
   "metadata": {
    "cellId": "eley78imblssu3r5j0pjkp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0ae6c4b3",
   "metadata": {
    "cellId": "sxgossa0t2sh8umwiownf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentences = batch_1['sentence'].to_list()\n",
    "\n",
    "#Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained('ai-forever/sbert_large_nlu_ru')\n",
    "model = AutoModel.from_pretrained('ai-forever/sbert_large_nlu_ru')\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, max_length=64, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "501b964b",
   "metadata": {
    "cellId": "ojh5kegc5jev7b3ouw1t9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentences_test = df_test['texts'].to_list()\n",
    "\n",
    "#Tokenize sentences\n",
    "encoded_input_test = tokenizer(sentences_test, padding=True, truncation=True, max_length=64, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0cf7ffac",
   "metadata": {
    "cellId": "r129rn4madik3c3gjtun2"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d02538b7",
   "metadata": {
    "cellId": "a2vfdqptgsg39amzypfyjy"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "with torch.no_grad():\n",
    "    model_output_test = model(**encoded_input_test)\n",
    "\n",
    "#Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings_test = mean_pooling(model_output_test, encoded_input_test['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7af0ec81",
   "metadata": {
    "cellId": "natxiim57hj1uemj7d24j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1024])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sentence_embeddings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6a75af5b",
   "metadata": {
    "cellId": "qi0n941vi4ucpf6umolbt"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentence_embeddings_test = sentence_embeddings_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8863a0b5",
   "metadata": {
    "cellId": "7r6sb23upgai3btbboptb"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_features, val_features, train_labels, val_labels = train_test_split(sentence_embeddings, batch_1['sentiment'].values, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "37e5f7d0",
   "metadata": {
    "cellId": "zes4hhpv2b8kuu47e29p0l"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b68b92b5493d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Make predictions on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my_pred_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgb_clf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Print classification report and confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_features' is not defined"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "# Train the model\n",
    "gb_clf_1 = GradientBoostingClassifier()\n",
    "gb_clf_1.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_1 = gb_clf_1.predict(val_features)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(val_labels, y_pred_1))\n",
    "print(confusion_matrix(val_labels, y_pred_1))\n",
    "\n",
    "# Print F1 score and ROC AUC score\n",
    "print(\"F1 score: \", f1_score(val_labels, y_pred_1, average='weighted'))\n",
    "print(\"ROC AUC score: \", roc_auc_score(val_labels, gb_clf_1.predict_proba(val_features), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9adba24f",
   "metadata": {
    "cellId": "nce31gfub57ctvi9ecmp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.88      0.93      0.91      1046\n",
      "           0       0.65      0.45      0.53       267\n",
      "           1       0.84      0.88      0.86       624\n",
      "\n",
      "    accuracy                           0.85      1937\n",
      "   macro avg       0.79      0.75      0.76      1937\n",
      "weighted avg       0.84      0.85      0.84      1937\n",
      "\n",
      "[[972  30  44]\n",
      " [ 86 119  62]\n",
      " [ 44  34 546]]\n",
      "F1 score:  0.8373213009746296\n",
      "ROC AUC score:  0.9313424692823705\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "y_pred_1 = gb_clf_1.predict(val_features)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(val_labels, y_pred_1))\n",
    "print(confusion_matrix(val_labels, y_pred_1))\n",
    "\n",
    "# Print F1 score and ROC AUC score\n",
    "print(\"F1 score: \", f1_score(val_labels, y_pred_1, average='weighted'))\n",
    "print(\"ROC AUC score: \", roc_auc_score(val_labels, gb_clf_1.predict_proba(val_features), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3e59c694",
   "metadata": {
    "cellId": "aj1kr6k42knk24uov9ldn"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot compare types 'ndarray(dtype=int64)' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-52fec5ced2ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'1category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Communication'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Quality'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Price'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Safety'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'?'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbatch_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4359\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m     ):\n\u001b[0;32m-> 4361\u001b[0;31m         return super().replace(\n\u001b[0m\u001b[1;32m   4362\u001b[0m             \u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6679\u001b[0m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6681\u001b[0;31m             return self.replace(\n\u001b[0m\u001b[1;32m   6682\u001b[0m                 \u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6683\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   4359\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pad\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4360\u001b[0m     ):\n\u001b[0;32m-> 4361\u001b[0;31m         return super().replace(\n\u001b[0m\u001b[1;32m   4362\u001b[0m             \u001b[0mto_replace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method)\u001b[0m\n\u001b[1;32m   6730\u001b[0m                         )\n\u001b[1;32m   6731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6732\u001b[0;31m                     new_data = self._data.replace_list(\n\u001b[0m\u001b[1;32m   6733\u001b[0m                         \u001b[0msrc_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6734\u001b[0m                         \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcomp\u001b[0;34m(s, regex)\u001b[0m\n\u001b[1;32m    608\u001b[0m                     \u001b[0mmaybe_convert_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masm8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 )\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_compare_or_regex_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_compare_or_regex_search\u001b[0;34m(a, b, regex)\u001b[0m\n\u001b[1;32m   1963\u001b[0m             \u001b[0mtype_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ndarray(dtype={dtype})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1965\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   1966\u001b[0m             \"Cannot compare types {a!r} and {b!r}\".format(\n\u001b[1;32m   1967\u001b[0m                 \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare types 'ndarray(dtype=int64)' and 'str'"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "batch_1['1category'] = batch_1['1category'].replace({'Communication': 1, 'Quality' : 2, 'Price' : 3, 'Safety': 4, '?': 0}).astype(int)\n",
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "55c610e9",
   "metadata": {
    "cellId": "5ladwhhiw5erptzpytcm6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_features_1, test_features_1, train_labels_1, test_labels_1 = train_test_split(sentence_embeddings, batch_1['1category'].values, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6695aa89",
   "metadata": {
    "cellId": "yjct47rld8dskc2s2uoc1s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.60      0.60       589\n",
      "           1       0.64      0.69      0.66       756\n",
      "           2       0.56      0.49      0.52       545\n",
      "           3       0.48      0.41      0.44        27\n",
      "           4       0.40      0.30      0.34        20\n",
      "\n",
      "    accuracy                           0.60      1937\n",
      "   macro avg       0.53      0.50      0.51      1937\n",
      "weighted avg       0.60      0.60      0.60      1937\n",
      "\n",
      "[[354 136  94   5   0]\n",
      " [113 524 112   0   7]\n",
      " [112 157 267   7   2]\n",
      " [ 12   1   3  11   0]\n",
      " [  4   7   3   0   6]]\n",
      "F1 score:  0.5969453474984489\n",
      "ROC AUC score:  0.8449519280749882\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# Train the model\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(train_features_1, train_labels_1)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_clf.predict(test_features_1)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(test_labels_1, y_pred))\n",
    "print(confusion_matrix(test_labels_1, y_pred))\n",
    "\n",
    "# Print F1 score and ROC AUC score\n",
    "print(\"F1 score: \", f1_score(test_labels_1, y_pred, average='weighted'))\n",
    "print(\"ROC AUC score: \", roc_auc_score(test_labels_1, gb_clf.predict_proba(test_features_1), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "270b4b72",
   "metadata": {
    "cellId": "cp4mmhk7fzv2xx6b858xjh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "np.savetxt('sentence_embeddings.csv',sentence_embeddings_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d6037",
   "metadata": {
    "cellId": "dg301zo8eheliu5gognzgs"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "proba = gb_clf_1.predict_proba(sentence_embeddings_test)\n",
    "\n",
    "# Создаем матрицу из вероятностей\n",
    "matrix = np.zeros((len(sentence_embeddings_test), 3))\n",
    "matrix[:, 0] = proba[:, 1] # Вероятности для класса 1\n",
    "matrix[:, 1] = proba[:, 0] # Вероятности для класса -1\n",
    "matrix[:, 2] = proba[:, 2] # Вероятности для класса 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "6a383b36",
   "metadata": {
    "cellId": "ngsm7yji7nmbec1wsos4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "proba_1 = gb_clf.predict_proba(sentence_embeddings_test)\n",
    "gb_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "4ff0b9ca",
   "metadata": {
    "cellId": "z6czzuzxovebc28lk78xa"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Создаем матрицу из вероятностей\n",
    "matrix_1 = np.zeros((len(sentence_embeddings_test), 4))\n",
    "matrix_1[:, 0] = proba_1[:, 1] / (1 - proba_1[:, 0]) # Вероятности для класса 1\n",
    "matrix_1[:, 1] = proba_1[:, 2] / (1 - proba_1[:, 0]) # Вероятности для класса 2\n",
    "matrix_1[:, 2] = proba_1[:, 3] / (1 - proba_1[:, 0]) # Вероятности для класса 3\n",
    "matrix_1[:, 3] = proba_1[:, 4] / (1 - proba_1[:, 0]) # Вероятности для класса 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "115f3423",
   "metadata": {
    "cellId": "vcloj8cjq4c8unzt28i8k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30274134, 0.44400757, 0.22415869, 0.00731952, 0.02177288],\n",
       "       [0.09430734, 0.42751179, 0.47169102, 0.00366162, 0.00282823],\n",
       "       [0.54935753, 0.11095213, 0.30189499, 0.03338186, 0.00441349],\n",
       "       ...,\n",
       "       [0.36478743, 0.36973302, 0.22276751, 0.03600327, 0.00670877],\n",
       "       [0.15363197, 0.29401752, 0.49982045, 0.01044684, 0.04208322],\n",
       "       [0.17344484, 0.42200103, 0.38426394, 0.01528497, 0.00500522]])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "proba_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b48682da",
   "metadata": {
    "cellId": "kc8ki9whvyp0yzlzd8aug"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4275117864701743"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "a = proba_1[1][:4]\n",
    "a_sorted = np.sort(a)\n",
    "a_sorted[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "71e26315",
   "metadata": {
    "cellId": "2ijeit7ub7ka9ijt6e8z96"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "matrix_2 = np.zeros((len(sentence_embeddings_test), 1))\n",
    "for i in range(matrix_2.shape[0]):\n",
    "    if np.argmax(proba_1[i]) != 4:\n",
    "        a = proba_1[i][:4]\n",
    "        a_sorted = np.sort(a)\n",
    "        if a_sorted[-2] > 0.3:\n",
    "            matrix_2[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "9f0cee33",
   "metadata": {
    "cellId": "7kt86wy4a4nrhn1ttopty"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "matrix_2 = np.zeros((len(sentence_embeddings_test), 1))\n",
    "for i in range(matrix_2.shape[0]):\n",
    "    a = proba_1[i]\n",
    "    if np.argmax(a) != 4:\n",
    "        a[np.argmax(a)] = 0\n",
    "        if np.argmax(a) != 4:\n",
    "            if max(a) > 0.4:\n",
    "                matrix_2[i] =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "5ac5f954",
   "metadata": {
    "cellId": "xw2yompzfukcfkzceulr0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "matrix_2.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a7cf0277",
   "metadata": {
    "cellId": "fogswxoo5sdvkw88ovvcfm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65518764, 0.331806  , 0.01300636],\n",
       "       [0.92307424, 0.05995717, 0.01696859],\n",
       "       [0.14268825, 0.42306587, 0.43424588],\n",
       "       ...,\n",
       "       [0.13638009, 0.70180912, 0.16181079],\n",
       "       [0.90180581, 0.07686215, 0.02133203],\n",
       "       [0.22092239, 0.14651349, 0.63256412]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "proba = gb_clf_1.predict_proba(sentence_embeddings_test)\n",
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "266b5869",
   "metadata": {
    "cellId": "6e2r2pm4t68qm5u8peydsa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  0,  1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "gb_clf_1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "92193be8",
   "metadata": {
    "cellId": "j7xni8mdtcko75ya8mfxx8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "matrix = np.zeros((len(sentence_embeddings_test), 3))\n",
    "matrix[:, 0] = proba[:, 2] # Вероятности для класса +\n",
    "matrix[:, 1] = proba[:, 0] # Вероятности для класса -\n",
    "matrix[:, 2] = proba[:, 1] # Вероятности для класса ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ce9b3798",
   "metadata": {
    "cellId": "sg73f37irir8ob390gtpzh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01300636, 0.65518764, 0.331806  ],\n",
       "       [0.01696859, 0.92307424, 0.05995717],\n",
       "       [0.43424588, 0.14268825, 0.42306587],\n",
       "       ...,\n",
       "       [0.16181079, 0.13638009, 0.70180912],\n",
       "       [0.02133203, 0.90180581, 0.07686215],\n",
       "       [0.63256412, 0.22092239, 0.14651349]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "09eca2f1",
   "metadata": {
    "cellId": "gvdfsodxb7rwdrx37lqi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01300636, 0.65518764, 0.331806  ],\n",
       "       [0.01696859, 0.92307424, 0.05995717],\n",
       "       [0.43424588, 0.14268825, 0.42306587],\n",
       "       ...,\n",
       "       [0.16181079, 0.13638009, 0.70180912],\n",
       "       [0.02133203, 0.90180581, 0.07686215],\n",
       "       [0.63256412, 0.22092239, 0.14651349]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "7fa166a2",
   "metadata": {
    "cellId": "ph3zt8oekvnj5fxsmbtkhq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63679033, 0.3214857 , 0.01049757, 0.0312264 ],\n",
       "       [0.47202744, 0.52080694, 0.00404289, 0.00312272],\n",
       "       [0.24620877, 0.66992131, 0.07407615, 0.00979378],\n",
       "       ...,\n",
       "       [0.58206187, 0.35069757, 0.05667909, 0.01056146],\n",
       "       [0.34738732, 0.59054741, 0.01234314, 0.04972213],\n",
       "       [0.51055398, 0.46489812, 0.01849238, 0.00605552]])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "matrix_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "20d01454",
   "metadata": {
    "cellId": "03jge8o3oc0atbj8avra23k"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "df_res = pd.DataFrame(df_test['texts'])\n",
    "df_res['+'] = matrix[:, 0]\n",
    "df_res['-'] = matrix[:, 1]\n",
    "df_res['?'] = matrix[:, 2]\n",
    "df_res['communication'] = matrix_1[:, 0]\n",
    "df_res['quality'] = matrix_1[:, 1]\n",
    "df_res['price'] = matrix_1[:, 2]\n",
    "df_res['safety'] = matrix_1[:, 3]\n",
    "df_res['second_category'] = matrix_2[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1abeec7c",
   "metadata": {
    "cellId": "20xgews0ka7ncljvrsfwbe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>+</th>\n",
       "      <th>-</th>\n",
       "      <th>?</th>\n",
       "      <th>communication</th>\n",
       "      <th>quality</th>\n",
       "      <th>price</th>\n",
       "      <th>safety</th>\n",
       "      <th>second_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15032022 обратился горячую линию закрытия счет...</td>\n",
       "      <td>0.013006</td>\n",
       "      <td>0.655188</td>\n",
       "      <td>0.331806</td>\n",
       "      <td>0.636790</td>\n",
       "      <td>0.321486</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>который год ткб решается глобальная проблема о...</td>\n",
       "      <td>0.016969</td>\n",
       "      <td>0.923074</td>\n",
       "      <td>0.059957</td>\n",
       "      <td>0.472027</td>\n",
       "      <td>0.520807</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>добрый день хочу оставить отзыв пользовании де...</td>\n",
       "      <td>0.434246</td>\n",
       "      <td>0.142688</td>\n",
       "      <td>0.423066</td>\n",
       "      <td>0.246209</td>\n",
       "      <td>0.669921</td>\n",
       "      <td>0.074076</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>добрый день сегодня зайдя свой личный кабинет ...</td>\n",
       "      <td>0.033727</td>\n",
       "      <td>0.877490</td>\n",
       "      <td>0.088784</td>\n",
       "      <td>0.283947</td>\n",
       "      <td>0.678202</td>\n",
       "      <td>0.010442</td>\n",
       "      <td>0.027409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>обслуживаюсь тинькофф пару лет возникла жесточ...</td>\n",
       "      <td>0.524833</td>\n",
       "      <td>0.304776</td>\n",
       "      <td>0.170392</td>\n",
       "      <td>0.254734</td>\n",
       "      <td>0.709914</td>\n",
       "      <td>0.025707</td>\n",
       "      <td>0.009645</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>отвратительный сервис отношение клиентам являю...</td>\n",
       "      <td>0.016710</td>\n",
       "      <td>0.939204</td>\n",
       "      <td>0.044086</td>\n",
       "      <td>0.546683</td>\n",
       "      <td>0.433741</td>\n",
       "      <td>0.008611</td>\n",
       "      <td>0.010965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>28042022 обратилась банк возможности перевода ...</td>\n",
       "      <td>0.107632</td>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.720628</td>\n",
       "      <td>0.523388</td>\n",
       "      <td>0.384195</td>\n",
       "      <td>0.083461</td>\n",
       "      <td>0.008956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>начале 2021 года акция выплате 8 кешбека оплат...</td>\n",
       "      <td>0.161811</td>\n",
       "      <td>0.136380</td>\n",
       "      <td>0.701809</td>\n",
       "      <td>0.582062</td>\n",
       "      <td>0.350698</td>\n",
       "      <td>0.056679</td>\n",
       "      <td>0.010561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>бездействие банка некомпетентность сотрудников...</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.901806</td>\n",
       "      <td>0.076862</td>\n",
       "      <td>0.347387</td>\n",
       "      <td>0.590547</td>\n",
       "      <td>0.012343</td>\n",
       "      <td>0.049722</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>потрачено 5 часов произвести оплату обучение о...</td>\n",
       "      <td>0.632564</td>\n",
       "      <td>0.220922</td>\n",
       "      <td>0.146513</td>\n",
       "      <td>0.510554</td>\n",
       "      <td>0.464898</td>\n",
       "      <td>0.018492</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts  ...  second_category\n",
       "0    15032022 обратился горячую линию закрытия счет...  ...              0.0\n",
       "1    который год ткб решается глобальная проблема о...  ...              1.0\n",
       "2    добрый день хочу оставить отзыв пользовании де...  ...              0.0\n",
       "3    добрый день сегодня зайдя свой личный кабинет ...  ...              0.0\n",
       "4    обслуживаюсь тинькофф пару лет возникла жесточ...  ...              0.0\n",
       "..                                                 ...  ...              ...\n",
       "995  отвратительный сервис отношение клиентам являю...  ...              0.0\n",
       "996  28042022 обратилась банк возможности перевода ...  ...              0.0\n",
       "997  начале 2021 года акция выплате 8 кешбека оплат...  ...              0.0\n",
       "998  бездействие банка некомпетентность сотрудников...  ...              0.0\n",
       "999  потрачено 5 часов произвести оплату обучение о...  ...              0.0\n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "801c8b7a",
   "metadata": {
    "cellId": "yho5exycd9g57qcqwzgmsk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "df_res['second_category'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4a25c",
   "metadata": {
    "cellId": "5fhdf7gus04vnomndxrouh"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "df.to_csv('file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f246f",
   "metadata": {
    "cellId": "xbp0fj6mvfhb4ce9bqxr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60779fe",
   "metadata": {
    "cellId": "a1hdxnfmzduwt388g2n6l"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513851bd",
   "metadata": {
    "cellId": "5h6lqzkxa0urzsu0ihpl3d"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca41c7",
   "metadata": {
    "cellId": "9phbfwrsvml7oxs7o5nh87"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1c172",
   "metadata": {
    "cellId": "mi1fcuckmkwbfewac4b4"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333e47f",
   "metadata": {
    "cellId": "8ejns9115lq0f1orso43u4i"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0337190",
   "metadata": {
    "cellId": "2yx07zecrsos6b0q4ohg8"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e68f31",
   "metadata": {
    "cellId": "kdttw44n5szrq0y6z8u1"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c7d1fbf7",
   "metadata": {
    "cellId": "fczbeu646hlfh8w8i5qt4u"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "sentence_embeddings = sentence_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6bb94659",
   "metadata": {
    "cellId": "u3hmpyfs8xgyfnqacafs6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17589381, -0.44548932, -1.1525593 , ...,  0.2932805 ,\n",
       "         0.23557892, -0.02581333],\n",
       "       [ 0.24762441, -0.27591145,  0.05957773, ...,  0.47680297,\n",
       "         0.41355518,  0.3928501 ],\n",
       "       [ 0.44421795, -0.27066076, -0.48516497, ...,  0.2548896 ,\n",
       "        -0.11006395,  0.05882683],\n",
       "       ...,\n",
       "       [ 0.7813839 , -0.26912764,  0.25833383, ...,  0.15924703,\n",
       "         0.6319809 ,  0.9049467 ],\n",
       "       [ 0.40376845, -0.30254105, -0.4711971 , ...,  0.38173667,\n",
       "         0.17347988,  0.7489807 ],\n",
       "       [ 0.32993773, -0.17225449, -0.06562295, ...,  0.5437628 ,\n",
       "         0.21455204,  0.6298423 ]], dtype=float32)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbae303",
   "metadata": {
    "cellId": "aol085tw3tca4q7yo0888"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b54d2ab",
   "metadata": {
    "cellId": "6yi0gmzx8dvkiv1uk9zkp"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb4613",
   "metadata": {
    "cellId": "z2p2qwl94vdk9owyvtisc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "86e28f6b",
   "metadata": {
    "cellId": "vveeyz9mcf9emiene0bsh"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15a1e1cfdbc545a195fb8433807b0a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=995526.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a17683f0be49dd911382702b7ef0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513fd5bdd7f84c5796618f117c3223e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1961828.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa22a4b59564edd98bb88612ea939b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type bert to instantiate a model of type distilbert. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ba0f33ed2f4ce6bfa0cc86505e2ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=714314041.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing DistilBertModel: ['bert.encoder.layer.7.attention.self.value.weight', 'bert.embeddings.position_embeddings.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.query.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.pooler.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.bias', 'bert.pooler.dense.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.embeddings.token_type_embeddings.weight', 'cls.predictions.bias', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.bias', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.attention.output.dense.bias', 'cls.predictions.decoder.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.8.output.dense.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertModel were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['transformer.layer.9.attention.out_lin.weight', 'transformer.layer.3.attention.q_lin.weight', 'transformer.layer.0.attention.k_lin.weight', 'transformer.layer.6.ffn.lin2.bias', 'transformer.layer.0.ffn.lin1.bias', 'transformer.layer.7.attention.k_lin.bias', 'transformer.layer.7.ffn.lin1.bias', 'transformer.layer.10.output_layer_norm.bias', 'transformer.layer.9.attention.v_lin.bias', 'transformer.layer.2.attention.q_lin.bias', 'transformer.layer.8.sa_layer_norm.bias', 'transformer.layer.4.output_layer_norm.bias', 'transformer.layer.5.output_layer_norm.bias', 'transformer.layer.11.sa_layer_norm.bias', 'transformer.layer.10.ffn.lin1.bias', 'transformer.layer.0.attention.out_lin.bias', 'transformer.layer.10.attention.q_lin.weight', 'transformer.layer.5.ffn.lin2.bias', 'transformer.layer.11.attention.out_lin.bias', 'transformer.layer.9.sa_layer_norm.bias', 'transformer.layer.6.attention.out_lin.bias', 'transformer.layer.3.ffn.lin2.weight', 'transformer.layer.5.attention.q_lin.weight', 'transformer.layer.2.attention.k_lin.bias', 'transformer.layer.5.attention.k_lin.weight', 'transformer.layer.5.attention.v_lin.bias', 'transformer.layer.2.output_layer_norm.bias', 'transformer.layer.8.ffn.lin2.weight', 'transformer.layer.2.sa_layer_norm.bias', 'transformer.layer.2.attention.v_lin.bias', 'transformer.layer.7.ffn.lin2.weight', 'transformer.layer.5.ffn.lin1.bias', 'transformer.layer.5.attention.out_lin.bias', 'transformer.layer.3.ffn.lin1.weight', 'transformer.layer.4.attention.out_lin.weight', 'transformer.layer.7.sa_layer_norm.weight', 'transformer.layer.0.attention.q_lin.weight', 'transformer.layer.10.attention.v_lin.weight', 'transformer.layer.1.sa_layer_norm.weight', 'embeddings.LayerNorm.bias', 'transformer.layer.3.sa_layer_norm.weight', 'embeddings.word_embeddings.weight', 'transformer.layer.6.sa_layer_norm.bias', 'transformer.layer.10.attention.k_lin.weight', 'transformer.layer.0.ffn.lin2.bias', 'transformer.layer.1.ffn.lin1.bias', 'transformer.layer.1.ffn.lin2.bias', 'transformer.layer.3.attention.v_lin.bias', 'transformer.layer.3.attention.out_lin.weight', 'transformer.layer.5.sa_layer_norm.bias', 'transformer.layer.5.attention.k_lin.bias', 'transformer.layer.3.ffn.lin2.bias', 'transformer.layer.9.attention.out_lin.bias', 'transformer.layer.11.ffn.lin2.weight', 'transformer.layer.5.attention.v_lin.weight', 'transformer.layer.6.output_layer_norm.bias', 'transformer.layer.1.output_layer_norm.weight', 'transformer.layer.4.sa_layer_norm.bias', 'transformer.layer.6.attention.v_lin.bias', 'transformer.layer.9.attention.q_lin.weight', 'transformer.layer.1.attention.k_lin.weight', 'transformer.layer.3.attention.q_lin.bias', 'transformer.layer.9.attention.q_lin.bias', 'transformer.layer.7.output_layer_norm.bias', 'transformer.layer.1.ffn.lin1.weight', 'transformer.layer.1.attention.q_lin.weight', 'transformer.layer.7.attention.k_lin.weight', 'transformer.layer.2.attention.out_lin.weight', 'transformer.layer.8.ffn.lin1.weight', 'transformer.layer.0.sa_layer_norm.bias', 'transformer.layer.8.attention.q_lin.weight', 'transformer.layer.8.attention.v_lin.bias', 'transformer.layer.4.ffn.lin2.bias', 'transformer.layer.1.attention.v_lin.weight', 'transformer.layer.3.output_layer_norm.weight', 'transformer.layer.10.attention.k_lin.bias', 'transformer.layer.9.sa_layer_norm.weight', 'transformer.layer.6.attention.out_lin.weight', 'embeddings.LayerNorm.weight', 'transformer.layer.1.attention.k_lin.bias', 'transformer.layer.11.output_layer_norm.weight', 'transformer.layer.3.sa_layer_norm.bias', 'transformer.layer.0.attention.v_lin.bias', 'transformer.layer.0.output_layer_norm.weight', 'transformer.layer.7.ffn.lin2.bias', 'transformer.layer.6.attention.q_lin.weight', 'transformer.layer.9.ffn.lin1.bias', 'transformer.layer.0.attention.out_lin.weight', 'transformer.layer.10.output_layer_norm.weight', 'transformer.layer.4.attention.v_lin.bias', 'transformer.layer.9.ffn.lin1.weight', 'transformer.layer.2.attention.q_lin.weight', 'transformer.layer.5.attention.q_lin.bias', 'transformer.layer.4.ffn.lin1.weight', 'transformer.layer.3.attention.v_lin.weight', 'transformer.layer.11.sa_layer_norm.weight', 'transformer.layer.0.sa_layer_norm.weight', 'transformer.layer.7.attention.out_lin.bias', 'transformer.layer.4.attention.q_lin.bias', 'transformer.layer.4.attention.out_lin.bias', 'transformer.layer.8.output_layer_norm.bias', 'transformer.layer.7.attention.q_lin.bias', 'transformer.layer.11.attention.k_lin.weight', 'transformer.layer.6.output_layer_norm.weight', 'transformer.layer.10.attention.q_lin.bias', 'transformer.layer.9.ffn.lin2.weight', 'transformer.layer.3.attention.out_lin.bias', 'transformer.layer.7.output_layer_norm.weight', 'transformer.layer.8.ffn.lin1.bias', 'transformer.layer.2.ffn.lin1.bias', 'transformer.layer.8.output_layer_norm.weight', 'transformer.layer.9.attention.v_lin.weight', 'transformer.layer.11.attention.q_lin.weight', 'transformer.layer.0.attention.v_lin.weight', 'transformer.layer.8.attention.k_lin.weight', 'transformer.layer.4.attention.k_lin.weight', 'transformer.layer.4.ffn.lin2.weight', 'transformer.layer.10.ffn.lin2.weight', 'transformer.layer.11.attention.v_lin.bias', 'transformer.layer.3.attention.k_lin.weight', 'transformer.layer.6.attention.k_lin.weight', 'transformer.layer.5.ffn.lin2.weight', 'transformer.layer.6.sa_layer_norm.weight', 'transformer.layer.9.output_layer_norm.bias', 'transformer.layer.9.attention.k_lin.weight', 'transformer.layer.2.attention.k_lin.weight', 'transformer.layer.2.sa_layer_norm.weight', 'transformer.layer.0.attention.k_lin.bias', 'transformer.layer.4.output_layer_norm.weight', 'transformer.layer.11.attention.out_lin.weight', 'transformer.layer.1.attention.out_lin.bias', 'transformer.layer.1.sa_layer_norm.bias', 'transformer.layer.3.ffn.lin1.bias', 'transformer.layer.7.attention.q_lin.weight', 'transformer.layer.2.attention.out_lin.bias', 'transformer.layer.1.attention.out_lin.weight', 'transformer.layer.1.output_layer_norm.bias', 'transformer.layer.9.attention.k_lin.bias', 'transformer.layer.8.attention.k_lin.bias', 'transformer.layer.7.attention.v_lin.weight', 'transformer.layer.5.sa_layer_norm.weight', 'transformer.layer.11.ffn.lin1.weight', 'transformer.layer.8.sa_layer_norm.weight', 'transformer.layer.2.ffn.lin2.weight', 'transformer.layer.7.attention.out_lin.weight', 'transformer.layer.11.ffn.lin1.bias', 'transformer.layer.0.ffn.lin2.weight', 'transformer.layer.4.attention.v_lin.weight', 'transformer.layer.11.attention.q_lin.bias', 'transformer.layer.3.output_layer_norm.bias', 'transformer.layer.10.sa_layer_norm.bias', 'transformer.layer.10.attention.out_lin.weight', 'transformer.layer.4.attention.k_lin.bias', 'transformer.layer.3.attention.k_lin.bias', 'transformer.layer.7.sa_layer_norm.bias', 'transformer.layer.2.ffn.lin2.bias', 'transformer.layer.6.ffn.lin1.bias', 'transformer.layer.0.ffn.lin1.weight', 'transformer.layer.9.ffn.lin2.bias', 'transformer.layer.10.attention.v_lin.bias', 'transformer.layer.10.ffn.lin2.bias', 'transformer.layer.11.attention.k_lin.bias', 'transformer.layer.6.attention.k_lin.bias', 'transformer.layer.9.output_layer_norm.weight', 'embeddings.position_embeddings.weight', 'transformer.layer.4.sa_layer_norm.weight', 'transformer.layer.8.ffn.lin2.bias', 'transformer.layer.6.attention.q_lin.bias', 'transformer.layer.10.ffn.lin1.weight', 'transformer.layer.1.ffn.lin2.weight', 'transformer.layer.8.attention.v_lin.weight', 'transformer.layer.0.attention.q_lin.bias', 'transformer.layer.5.attention.out_lin.weight', 'transformer.layer.8.attention.out_lin.weight', 'transformer.layer.4.ffn.lin1.bias', 'transformer.layer.6.attention.v_lin.weight', 'transformer.layer.0.output_layer_norm.bias', 'transformer.layer.1.attention.v_lin.bias', 'transformer.layer.11.ffn.lin2.bias', 'transformer.layer.5.ffn.lin1.weight', 'transformer.layer.4.attention.q_lin.weight', 'transformer.layer.7.attention.v_lin.bias', 'transformer.layer.2.ffn.lin1.weight', 'transformer.layer.5.output_layer_norm.weight', 'transformer.layer.2.attention.v_lin.weight', 'transformer.layer.2.output_layer_norm.weight', 'transformer.layer.6.ffn.lin1.weight', 'transformer.layer.6.ffn.lin2.weight', 'transformer.layer.11.attention.v_lin.weight', 'transformer.layer.8.attention.out_lin.bias', 'transformer.layer.10.attention.out_lin.bias', 'transformer.layer.8.attention.q_lin.bias', 'transformer.layer.11.output_layer_norm.bias', 'transformer.layer.10.sa_layer_norm.weight', 'transformer.layer.1.attention.q_lin.bias', 'transformer.layer.7.ffn.lin1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (\n",
    "    ppb.DistilBertModel, ppb.DistilBertTokenizer, 'bert-base-multilingual-cased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b02dc01",
   "metadata": {
    "cellId": "gk2mrv1eirqkuaz07u9wul"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726eec09",
   "metadata": {
    "cellId": "b7wk5x88wmc2bbim8jas33"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "996b61d4",
   "metadata": {
    "cellId": "8kyp5hiiawrhh2uq8wentc"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "tokenized = batch_1['sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a94f0959",
   "metadata": {
    "cellId": "aa145sf6fpevzlz4651j"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "49c44dbc",
   "metadata": {
    "cellId": "b7kga7q9qqwzmag5453izl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19361, 156)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "68528013",
   "metadata": {
    "cellId": "xou1qbz9swp3peewmnf6sv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19361, 156)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "61289fbf",
   "metadata": {
    "cellId": "hi7mpnssl1pu6bqza9zowq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  101, 15717, 53204, ...,     0,     0,     0],\n",
       "       [  101,  5796,  1788, ...,     0,     0,     0],\n",
       "       [  101, 21413,   391, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  7943,   736, ...,     0,     0,     0],\n",
       "       [  101,  6378,  4170, ...,     0,     0,     0],\n",
       "       [  101, 22263,  4191, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7852eaba",
   "metadata": {
    "cellId": "pg9fdlbyquh3gqjw63mvs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "cd4d233c",
   "metadata": {
    "cellId": "lpxdxovzwom5vquxwk5hpd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-57-91558123792c>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_mask = torch.tensor(attention_mask)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:71] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 12371214336 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-91558123792c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlast_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mhead_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_head_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m    993\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"absolute\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:71] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 12371214336 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a26ae",
   "metadata": {
    "cellId": "o5rm9ir8m1hcekw9rrkjue"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85563357",
   "metadata": {
    "cellId": "xsxemskpvnszu8aijpzpr"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac31e9",
   "metadata": {
    "cellId": "y7h3ogqaknj101xf2qqlv3"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0018c855",
   "metadata": {
    "cellId": "hsqrxhphemndxp1ka153t"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "labels = batch_1['sentiment']\n",
    "labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "66c6f652",
   "metadata": {
    "cellId": "psn95naglwrxprqf20q6g"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>1category</th>\n",
       "      <th>2category</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4754</td>\n",
       "      <td>При этом всегда получал качественные услуги.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4417</td>\n",
       "      <td>Не вижу, за что хотя бы 2 поставить, сервис на 1!</td>\n",
       "      <td>?</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3629</td>\n",
       "      <td>Вот так \"Мой любимый\" банк МКБ меня обманул.</td>\n",
       "      <td>?</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11640</td>\n",
       "      <td>Отвратительное отношение к клиентам.</td>\n",
       "      <td>Communication</td>\n",
       "      <td>None</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5571</td>\n",
       "      <td>Всегда в любое время дня и ночи помогут, ответ...</td>\n",
       "      <td>Communication</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ... sentiment\n",
       "0        4754  ...         1\n",
       "1        4417  ...        -1\n",
       "2        3629  ...        -1\n",
       "3       11640  ...        -1\n",
       "4        5571  ...         1\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "#batch_1['sentiment'] = batch_1['sentiment'].replace({'−': -1, '+': 1, '?': 0}).astype(int)\n",
    "batch_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b209f48",
   "metadata": {
    "cellId": "3ykfqyv4krfhs260clmw34"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0174b490",
   "metadata": {
    "cellId": "78uygxglw8kgassv6za23b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "# Train the model\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(train_features, train_labels)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = gb_clf.predict(test_features)\n",
    "\n",
    "# Print classification report and confusion matrix\n",
    "print(classification_report(test_labels, y_pred))\n",
    "print(confusion_matrix(test_labels, y_pred))\n",
    "\n",
    "# Print F1 score and ROC AUC score\n",
    "print(\"F1 score: \", f1_score(test_labels, y_pred, average='weighted'))\n",
    "print(\"ROC AUC score: \", roc_auc_score(test_labels, gb_clf.predict_proba(test_features), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "221ffd22",
   "metadata": {
    "cellId": "92wt0sloausof3i2kohqh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "80480e06",
   "metadata": {
    "cellId": "macmsi1kqops6d7m821xd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!g1.1\n",
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a64018d",
   "metadata": {
    "cellId": "jtq976nyhipkg54t7i6rp9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7ed25935",
   "metadata": {
    "cellId": "mznxgp7vv486qyv3w1p4ht"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81a97a68",
   "metadata": {
    "cellId": "xl6tsjwqcloooi79qmv9zm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.89      0.76       253\n",
      "           0       0.40      0.14      0.21        85\n",
      "           1       0.67      0.54      0.60       162\n",
      "\n",
      "    accuracy                           0.65       500\n",
      "   macro avg       0.58      0.52      0.52       500\n",
      "weighted avg       0.62      0.65      0.61       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "# инициализация SVM-классификатора\n",
    "svc = SVC()\n",
    "\n",
    "# определение сетки гиперпараметров для поиска по кросс-валидации\n",
    "parameters = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10]}\n",
    "\n",
    "# поиск наилучших гиперпараметров\n",
    "clf_svm = GridSearchCV(svc, parameters, cv=5)\n",
    "clf_svm.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "# вывод наилучших гиперпараметров и метрик качества на тестовом наборе данных\n",
    "print(\"Best Parameters: \", clf_svm.best_params_)\n",
    "svm_pred = clf_svm.predict(test_features)\n",
    "print(classification_report(test_labels, svm_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0aa0b9",
   "metadata": {
    "cellId": "890bbuv9j8c8tudogwa027",
    "execution_id": "d0237561-ddf2-4f3e-b088-63242affb995"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# инициализация CatBoost-классификатора\n",
    "cat_clf = CatBoostClassifier(loss_function='MultiClass', eval_metric='Accuracy')\n",
    "\n",
    "# определение сетки гиперпараметров для поиска по кросс-валидации\n",
    "parameters = {'iterations': [100, 500, 1000], 'learning_rate': [0.01, 0.1, 1], 'depth': [3, 5, 7]}\n",
    "\n",
    "# поиск наилучших гиперпараметров\n",
    "clf_cat = GridSearchCV(cat_clf, parameters, cv=5)\n",
    "clf_cat.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "# вывод наилучших гиперпараметров и метрик качества на тестовом наборе данных\n",
    "print(\"Best Parameters: \", clf_cat.best_params_)\n",
    "cat_pred = clf_cat.predict(test_features)\n",
    "print(classification_report(test_labels, cat_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "6448ce19-1e8d-473d-a112-2d271c376934",
  "notebookPath": ".git/Untitled1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
